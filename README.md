# Awsome Video Diffusion [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
A list of recent video diffusion papers for generation, editing, enhancement and understanding. 


### Opensource Toolboxes and Foudation Models 
+ [Videocrafter](https://github.com/VideoCrafter/VideoCrafter) 
+ [ModelScope](https://modelscope.cn/models/damo/text-to-video-synthesis/summary)

### Video Diffusion for Generation 
+ [Physics-Driven Diffusion Models for Impact Sound Synthesis from Videos](https://arxiv.org/abs/2303.16897)(CVPR 2023) 
 
  [![Star](https://img.shields.io/github/stars/facebookresearch/segment-anything.svg?style=social&label=Star)](https://github.com/sukun1045/video-physics-sound-diffusion) [[arxiv]](https://arxiv.org/abs/2303.16897) [[project page]](https://sukun1045.github.io/video-physics-sound-diffusion/) 

+ [Seer: Language Instructed Video Prediction with Latent Diffusion Models](https://arxiv.org/abs/2303.14897)(Mar., 2023)  
  [[github]](https://seervideodiffusion.github.io/) [[arxiv]](https://arxiv.org/abs/2303.14897) [[project page]](https://seervideodiffusion.github.io/) 

+ [Text2video-Zero: Text-to-Image Diffusion Models Are Zero-Shot Video Generators](https://arxiv.org/abs/2303.13439)(Mar., 2023)   
  [[github]](https://github.com/Picsart-AI-Research/Text2Video-Zero) [[arxiv]](https://arxiv.org/abs/2303.13439) [[project page]](https://text2video-zero.github.io/) 
  
+ [Conditional Image-to-Video Generation with Latent Flow Diffusion Models](https://arxiv.org/abs/2303.13744)(CVPR 2023)   
  [[github]](https://github.com/nihaomiao/CVPR23_LFDM) [[arxiv]](https://arxiv.org/abs/2303.13744) [project page]

+ [Decomposed Diffusion Models for High-Quality Video Generation](https://arxiv.org/abs/2303.08320)(CVPR 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2303.08320) [[project page]](https://modelscope.cn/models/damo/text-to-video-synthesis/summary) 

+ [Video Probabilistic Diffusion Models in Projected Latent Space](https://arxiv.org/abs/2302.07685)(CVPR 2023)   
  [[github]](https://github.com/sihyun-yu/PVDM) [[arxiv]](https://arxiv.org/abs/2302.07685) [[project page]](https://sihyun.me/PVDM/) 

+ [Structure and Content-Guided Video Synthesis With Diffusion Models](https://arxiv.org/abs/2302.03011)(Feb., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2302.03011) [[project page]](https://research.runwayml.com/gen2) 

+ [Tune-a-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation](https://arxiv.org/abs/2212.11565)(Dec., 2022)   
  [[github]](https://github.com/showlab/Tune-A-Video) [[arxiv]](https://arxiv.org/abs/2212.11565) [[project page]](https://tuneavideo.github.io/) 

+ [Mm-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation](https://arxiv.org/abs/2212.09478)(CVPR 2023)   
  [[github]](https://github.com/researchmm/MM-Diffusion) [[arxiv]](https://arxiv.org/abs/2212.09478) [project page] 

+ [Magvit: Masked Generative Video Transformer](https://arxiv.org/abs/2212.05199)(Dec., 2022)    
  [[github]](https://github.com/MAGVIT/magvit) [[arxiv]](https://arxiv.org/abs/2212.05199) [[project page]](https://magvit.cs.cmu.edu/) 

+ [VIDM: Video Implicit Diffusion Models](https://arxiv.org/abs/2212.00235)(AAAI 2023)   
  [[github]](https://github.com/MKFMIKU/VIDM) [[arxiv]](https://arxiv.org/abs/2212.00235) [[project page]](https://kfmei.page/vidm/) 

+ [Latent Video Diffusion Models for High-Fidelity Video Generation With Arbitrary Lengths](https://arxiv.org/abs/2211.13221)(Nov., 2022)   
  [[github]](https://github.com/YingqingHe/LVDM) [[arixv]](https://arxiv.org/abs/2211.13221) [[project page]](https://yingqinghe.github.io/LVDM/)

+ [SinFusion: Training Diffusion Models on a Single Image or Video](https://arxiv.org/abs/2211.11743)(Nov., 2022)   
  [[github]](https://github.com/yanivnik/sinfusion-code) [arixv](https://arxiv.org/abs/2211.11743) [[project page]](https://yanivnik.github.io/sinfusion/)

+ [Magicvideo: Efficient Video Generation With Latent Diffusion Models](https://arxiv.org/abs/2211.11018)(Nov., 2022)   
  [github] [[arxiv]](https://arxiv.org/abs/2211.11018) [[project page]](https://magicvideo.github.io/#)

+ [Imagen Video: High Definition Video Generation With Diffusion Models](https://arxiv.org/abs/2210.02303)(Oct., 2022)   
  [github] [[arxiv]]((https://arxiv.org/abs/2210.02303)[[project page]](https://imagen.research.google/video/)

+ [Make-A-Video: Text-to-Video Generation without Text-Video Data](https://openreview.net/forum?id=nJfylDvgzlq)(ICLR 2023)   
  [github] [arixv](https://openreview.net/forum?id=nJfylDvgzlq) [[project page]](https://makeavideo.studio)

+ [Diffusion Models for Video Prediction and Infilling](https://arxiv.org/abs/2206.07696)(TMLR 2022)   
  [[github]](https://github.com/Tobi-r9/RaMViD) [[arxiv]](https://arxiv.org/abs/2206.07696) [[project page]](https://sites.google.com/view/video-diffusion-prediction)

+ [McVd: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853)(NeurIPS 2022)   
  [[github]](https://github.com/voletiv/mcvd-pytorch) [[project page]](https://mask-cond-video-diffusion.github.io)

+ [Video Diffusion Models](https://arxiv.org/abs/2204.03458)(April, 2022)   
  [github] [arixv](https://arxiv.org/abs/2204.03458) [[project page]](https://video-diffusion.github.io/)

+ [Diffusion Probabilistic Modeling for Video Generation](https://arxiv.org/abs/2203.09481)(March, 2022)   
  [[github]](https://github.com/buggyyang/RVD) [[arxiv]](https://arxiv.org/abs/2203.09481) [project page]

### Video Editing
+ [Soundini: Sound-Guided Diffusion for Natural Video Editing](https://arxiv.org/abs/2304.06818)(April, 2023)   
  [[github]](https://github.com/kuai-lab/soundini-official) [[arxiv]](https://arxiv.org/abs/2304.06818) [[project page]](https://kuai-lab.github.io/soundini-gallery/) 

+ [Zero-Shot Video Editing Using Off-the-Shelf Image Diffusion Models](https://arxiv.org/abs/2303.17599)(Mar., 2023)   
  [[github]](https://github.com/baaivision/vid2vid-zero) [[arxiv]](https://arxiv.org/abs/2303.17599) [[project page]](https://huggingface.co/spaces/BAAI/vid2vid-zero) 

+ [Pix2video: Video Editing Using Image Diffusion](https://arxiv.org/abs/2303.12688)(Mar., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2303.12688) [[project page]](https://duyguceylan.github.io/pix2video.github.io/) 

+ [Video-P2P: Video Editing with Cross-attention Control](https://arxiv.org/abs/2303.04761)(Mar., 2023)   
  [[github]](https://github.com/ShaoTengLiu/Video-P2P) [[arxiv]](https://arxiv.org/abs/2303.04761) [[project page]](https://video-p2p.github.io/)

+ [Dreamix: Video Diffusion Models Are General Video Editors](https://arxiv.org/abs/2302.01329)(Feb., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2302.01329) [[project page]](https://dreamix-video-editing.github.io/) 

+ [Shape-Aware Text-Driven Layered Video Editing](https://arxiv.org/abs/2301.13173)(Jan., 2023)    
  [github] [[arxiv]](https://arxiv.org/abs/2301.13173) [[project page]](https://text-video-edit.github.io/)   
+ [Speech Driven Video Editing via an Audio-Conditioned Diffusion Model](https://arxiv.org/abs/2301.04474)(Jan., 2023)   
  [[github]](https://github.com/DanBigioi/DiffusionVideoEditing) [[arxiv]](https://arxiv.org/abs/2301.04474) [[project page]](https://danbigioi.github.io/DiffusionVideoEditing/) 

+ [Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding](https://arxiv.org/abs/2212.02802)(CVPR 2023)  
  [[github]](https://github.com/man805/Diffusion-Video-Autoencoders) [[arxiv]](https://arxiv.org/abs/2212.02802) [[project page]](https://diff-video-ae.github.io/) 


### Long Form Video Generation and Completetion
+ [McVd: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation](https://arxiv.org/abs/2205.09853)(NeurIPS 2022)   
  [[github]](https://github.com/voletiv/mcvd-pytorch) [[arixv]](https://arxiv.org/abs/2205.09853) [[project page]](https://mask-cond-video-diffusion.github.io)

+ [Nuwa-Xl: Diffusion Over Diffusion for Extremely Long Video Generation](https://arxiv.org/abs/2303.12346)(Mar., 2023)   
  [github] [arixv](https://arxiv.org/abs/2303.12346) [[project page]](https://msra-nuwa.azurewebsites.net/#/)

+ [Flexible Diffusion Modeling of Long Videos](https://arxiv.org/abs/2205.11495) (May, 2022)   
  [[github]](https://github.com/plai-group/flexible-video-diffusion-modeling) [[arxiv]](https://arxiv.org/abs/2205.11495) [[project page]](https://fdmolv.github.io/)

### Video Enhancement and Restoration


+ [Ldmvfi: Video Frame Interpolation With Latent Diffusion Models](https://arxiv.org/abs/2303.09508)(Mar., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2303.09508) [project page]

+ [CaDM: Codec-aware Diffusion Modeling for Neural-enhanced Video Streaming](https://arxiv.org/abs/2211.08428)(Nov, 2022)   
  [github] [[arxiv]](https://arxiv.org/abs/2211.08428)


### 3D Video
+ [Learning 3D Photography Videos via Self-supervised Diffusion on Single Images](https://arxiv.org/abs/2302.10781)(Feb., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2302.10781) [project page] 

### Video Understanding

+ [Exploring Diffusion Models for Unsupervised Video Anomaly Detection](https://arxiv.org/abs/2304.05841)(Apr., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2304.05841) [project page]

+ [Pdpp:projected Diffusion for Procedure Planning in Instructional Videos](https://arxiv.org/abs/2303.14676)(CVPR 2023)   
  [github]](https://github.com/MCG-NJU/PDPP) [[arxiv]](https://arxiv.org/abs/2303.14676) [project page]

+ [Difftad: Temporal Action Detection With Proposal Denoising Diffusion](https://arxiv.org/abs/2303.14863)(Mar., 2023)     
  [[github]](https://github.com/sauradip/DiffusionTAD) [[arxiv]](https://arxiv.org/abs/2303.14863)

+ [Diffusionret: Generative Text-Video Retrieval With Diffusion Model](https://arxiv.org/abs/2303.09867) (Mar., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2303.09867) [project page]

+ [Refined Semantic Enhancement Towards Frequency Diffusion for Video Captioning](https://arxiv.org/abs/2211.15076)(Nov., 2022)   
  [[github]](https://github.com/lzp870/RSFD) [[arxiv]](https://arxiv.org/abs/2211.15076) [project page]

+ [A Generalist Framework for Panoptic Segmentation of Images and Videos](https://arxiv.org/abs/2210.06366)(Ocr. 2023)   
  [[github]](https://github.com/google-research/pix2seq) [[arxiv]](https://arxiv.org/abs/2210.06366) [project page]


### Healthcare and Biology
+ [Feature-Conditioned Cascaded Video Diffusion Models for Precise Echocardiogram Synthesis](https://arxiv.org/abs/2303.12644)(Mar., 2023)   
  [github] [[arxiv]](https://arxiv.org/abs/2303.12644) [project page]

+ [Neural Cell Video Synthesis via Optical-Flow Diffusion](https://arxiv.org/abs/2212.03250)(Dec., 2022)   
  [github] [[arxiv]](https://arxiv.org/abs/2212.03250) [project page]
